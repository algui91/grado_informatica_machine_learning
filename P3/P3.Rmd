---
title: "Aprendizaje Automático - Práctica 3"
author: "Alejandro Alcalde"
date: "05/05/2016"
fontsize: 10pt
monofont: "Source Code Pro Light"
# mathfont: "Source Code Pro Light"
# mainfont: "Ubuntu Light"
output:
  pdf_document:
    includes:
      in_header: header.tex
    latex_engine: xelatex
    toc: true
    highlight: tango
    # md_extensions: +latex_macros+raw_tex
# fc-list :outline -f "%{family}\n"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = T)
set.seed(1000000007)
```

```{r Load libraries, echo = F, include = F}
is.installed <- function(paquete) is.element(
  paquete, installed.packages())

if (!is.installed("dplyr"))
  install.packages("dplyr")
if (!is.installed("ggplot2"))
  install.packages("ggplot2")
if (!is.installed("GGally"))
  install.packages("GGally")
if (!is.installed("ISLR"))
  install.packages("ISLR")
if (!is.installed("gridExtra"))
  install.packages("gridExtra")
if (!is.installed("caret"))
  install.packages("caret")

library(dplyr)
library(ggplot2)
library(GGally)
library(ISLR)
library(gridExtra)
library(caret)
```

\newpage

# Ejercicio 1

__Usar el conjunto de datos Auto que es parte del paquete ISLR.__

__En este ejercicio desarrollaremos un modelo para predecir si un coche tiene un
consumo de carburante alto o bajo usando la base de datos Auto. Se considerará alto
cuando sea superior a la mediana de la variable mpg y bajo en caso contrario.__

- __Usar las funciones de R `pairs()` y `boxplot()` para investigar la dependencia entre
`mpg` y las otras características. ¿Cuáles de las otras características parece más
útil para predecir `mpg`? Justificar la respuesta. (0.5 puntos)__

En primer lugar cargaremos los datos, y vemos de qué tipo son:

```{r EXERCISE 1.A}
# Information dense summary of the data
(Auto <- dplyr::tbl_df(ISLR::Auto))
dplyr::glimpse(Auto)
```
```{r scatterplots, echo=F}
Auto$origin <- factor(Auto$origin)
GGally::ggpairs(Auto, aes(colour = origin, alpha = .5),
                 upper = list(continuous = wrap("cor", size = 2.5)),
                 lower = list(continuous = "points"),
                 diag = "blank", axisLabels = "none", columns = 1:7,
                 title = "Scatterplots of Auto Auto",
                 columnLabels = c("mpg", "cyl", "displ", "cv", "weight", "acc", "year"))
```

Los colores de los puntos corresponden al origen del coche (Americano, Europeo o
Japonés), se puede intuir que algunos coches gastan más en función del continente.

Como se aprecia en la gráfica, hay varias variables correlacionadas tanto positiva
como negativamente. Pero a nosotros solo nos interesan las relacionadas con el 
consumo de combustible. Con ello en mente, podríamos decir que las variables más 
correladas son la capacidad del motor (__Displacement__), el peso y la potencia
(__horsepower__) del coche. Veámoslas mejor:

```{r plotting corr vars, echo = F}
v <- Auto %>% dplyr::select(mpg, horsepower, weight, displacement, origin)

ggplot2::ggplot(data = v, aes(horsepower, mpg)) + 
  geom_point(aes(colour = origin)) + 
  theme_bw() + 
  scale_color_discrete(name = "Origin", labels = c("American", "European", "Japanese"))

ggplot2::ggplot(data = v, aes(weight, mpg)) + 
  geom_point(aes(colour = origin)) + 
  theme_bw() + 
  scale_color_discrete(name = "Origin", labels = c("American", "European", "Japanese"))

ggplot2::ggplot(data = v, aes(displacement, mpg)) + 
  geom_point(aes(colour = origin)) + 
  theme_bw() + 
  scale_color_discrete(name = "Origin", labels = c("American", "European", "Japanese"))
rm(v)
```

Veamos ahora la correlación mediante `boxplot`:

```{r Boxplots, echo = F}
Auto <- dplyr::mutate(Auto, mpg01 = as.factor(ifelse(mpg > median(mpg), 1, 0)))

bp1 <- ggplot(Auto) + geom_boxplot(aes(mpg01, cylinders)) + labs(x = "")
bp2 <- ggplot(Auto) + geom_boxplot(aes(mpg01, displacement)) + labs(x = "")
bp3 <- ggplot(Auto) + geom_boxplot(aes(mpg01, horsepower)) + labs(x = "")
bp4 <- ggplot(Auto) + geom_boxplot(aes(mpg01, weight)) + labs(x = "")
bp5 <- ggplot(Auto) + geom_boxplot(aes(mpg01, acceleration)) + labs(x = "")
bp6 <- ggplot(Auto) + geom_boxplot(aes(mpg01, year)) + labs(x = "")

grid.arrange(bp1, bp2, bp3, bp4, bp5, bp6,
             nrow = 2, ncol = 3,
             top = "Variables vs mpg01")
rm(bp1, bp2, bp3, bp4, bp5, bp6)
```

Como vemos, llegamos a la misma conclusión, la interpretación en boxplots es la
siguiente: Si los boxplots no se solapan entre sí, las variables están correladas.
Además, a mayor sea la distancia que los separa, más correladas estarán. Por tanto
salvo la aceleración y el año, el resto de variables están correladas en mayor o 
menor medida con las millas por galón de combustible que consume el coche.

- __Seleccionar las variables predictoras que considere más relevantes.__

Como hemos comentado en el punto anterior, las variables que parecen estar más
relacionadas con el consumo de combustible son `Horsepower, Weight` y `Displacement`.
Por lo tanto las usaremos como predictoras.

- __Particionar el conjunto de datos en un conjunto de entrenamiento ($80\%$) y otro
de test ($20\%$). Justificar el procedimiento usado.__

Para particionar los datos debemos asegurarnos que tanto la partición para training
como la de test mantengan la misma distribución, ya que de lo contrario podríamos
ajustar mal el modelo. Para conseguir esto, se hace uso de la librería `caret`
y su método `createDataPartition`. Ya que la variable `mpg` es contínua, se ha
decidido distribuir las muestas equitativamente en función del origien del coche.

Se ha creado un método `partitionDistribution` que muestra cómo se sigue manteniendo
la proporción de los datos tras el particionado. Esta estrategia se llama particionamiento
estratificado.

```{r EXERCISE 1.C}
partitionDistribution <- function(partition) {
  print(paste('Training: ', nrow(partition$training), 'instances'))
  print(summary(partition$training$origin) / nrow(partition$training) * 100)
  print(paste('Test: ', nrow(partition$test), 'instances'))
  print(summary(partition$test$origin)  / nrow(partition$test) * 100)
}

indexes <- createDataPartition(Auto$origin, p = .8, list = FALSE)
partition <- list(training = Auto[indexes,], test = Auto[-indexes,])
partitionDistribution(partition)
```

Podemos ver en la salida enterior como se ha mantenido la proporción de los 
orígenes de coches en ambas particiones.

- __Crear una variable binaria, `mpg01`, que será igual a $1$ si la variable `mpg`
contiene un valor por encima de la mediana, y $-1$ si `mpg` contiene un valor por
debajo. La mediana se puede calcular usando la función `median()`.__

```{r EXERCISE 1.D}
# A car has a low fuel comsumption if mpg is higher (It travels more milles per gallon of fuel).
# Consider the cars with mpg above the median as low consumption (1), and high
# comsumption those bellow the median
training <- dplyr::mutate(partition$training, mpg01 = ifelse(mpg > median(mpg), 1, 0))
test <- dplyr::mutate(partition$test, mpg01 = ifelse(mpg > median(mpg), 1, 0))
```

- __Ajustar un modelo de regresión Logística a los datos de entrenamiento y
predecir `mpg01` usando las variables seleccionadas en b). ¿Cuál es el error
de test del modelo? Justificar la respuesta. (1 punto)__

```{r EXERCISE 1.D.1}
glm.fit <- glm(mpg01 ~ horsepower + weight + displacement, 
               data = training, 
               family = binomial)

summary(glm.fit)

# Compute the test error
glm.probs <- predict(glm.fit, newdata = test, type = "response")

glm.pred <- rep("0", nrow(test))
glm.pred[glm.probs > .5] = "1"

contingency.table <- table(glm.pred, test$mpg01)
test.error <- mean(glm.pred != test$mpg01)
```

Para ajustar el modelo logístico se ha usado `glm`, la tabla de contingencia es la
siguiente:

|     	| $0$                          	| $1$                          	|
|-----	|------------------------------	|------------------------------	|
| $0$ 	| $`r contingency.table[1,1]`$ 	| $`r contingency.table[1,2]`$ 	|
| $1$ 	| $`r contingency.table[2,1]`$ 	| $`r contingency.table[2,2]`$ 	|


El error de test que hemos obtenido es del $`r (test.error)*100`\%$, lo cual 
quiere decir que estamos fallando en clasificar correctamente ese porcentaje de veces.

