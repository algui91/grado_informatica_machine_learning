---
title: "Aprendizaje Automático - Práctica 3"
author: "Alejandro Alcalde"
date: "05/05/2016"
fontsize: 10pt
monofont: "DejaVu Sans Mono"
# monofont: "Source Code Pro Light"
# mathfont: "Source Code Pro Light"
# mainfont: "Ubuntu Light"
output:
  pdf_document:
    includes:
      in_header: header.tex
    latex_engine: xelatex
    toc: true
    highlight: tango
    # md_extensions: +latex_macros+raw_tex
# fc-list :outline -f "%{family}\n"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Load libraries, echo = F, include = F}
is.installed <- function(paquete) is.element(
  paquete, installed.packages())

if (!is.installed("dplyr"))
  install.packages("dplyr")
if (!is.installed("ggplot2"))
  install.packages("ggplot2")
if (!is.installed("GGally"))
  install.packages("GGally")
if (!is.installed("ISLR"))
  install.packages("ISLR")
if (!is.installed("gridExtra"))
  install.packages("gridExtra")
if (!is.installed("caret"))
  install.packages("caret")
if (!is.installed("class"))
  install.packages("class")
if (!is.installed("parallel"))
  install.packages("parallel")
if (!is.installed("e1071"))
  install.packages("e1071")
if (!is.installed("plotROC"))
  install.packages("plotROC")

library(dplyr)
library(ggplot2)
library(GGally)
library(ISLR)
library(gridExtra)
library(caret)
library(class)
library(parallel)
library(e1071)
library(ROCR)
library(MASS)
library(plotROC)

devtools::install_github("hadley/ggplot2")
devtools::install_github("sachsmc/plotROC")

set.seed(1000000007)

GetParCluster <- function(seed = 1000000007) {
  # Calculate the number of cores
  cores.number <- detectCores()
  cl <- makeCluster(cores.number, type = "FORK")
  # Initialize seed
  clusterSetRNGStream(cl, iseed = seed)
  
  cl
}
```

\newpage

# Ejercicio 1

__Usar el conjunto de datos Auto que es parte del paquete ISLR.__

__En este ejercicio desarrollaremos un modelo para predecir si un coche tiene un
consumo de carburante alto o bajo usando la base de datos Auto. Se considerará alto
cuando sea superior a la mediana de la variable mpg y bajo en caso contrario.__

- __Usar las funciones de R `pairs()` y `boxplot()` para investigar la dependencia entre
`mpg` y las otras características. ¿Cuáles de las otras características parece más
útil para predecir `mpg`? Justificar la respuesta. (0.5 puntos)__

En primer lugar cargaremos los datos, y vemos de qué tipo son:

```{r EXERCISE 1.A}
# Information dense summary of the data
(Auto <- dplyr::tbl_df(ISLR::Auto))
dplyr::glimpse(Auto)
Auto <- Auto %>% dplyr::select(-name)
```
```{r scatterplots, echo=F}
debug <- F
Auto$origin <- factor(Auto$origin)
if (!debug){
GGally::ggpairs(Auto, aes(colour = origin, alpha = .5),
                 upper = list(continuous = wrap("cor", size = 2.5)),
                 lower = list(continuous = "points"),
                 diag = "blank", axisLabels = "none", columns = 1:7,
                 title = "Scatterplots of Auto Auto",
                 columnLabels = c("mpg", "cyl", "displ", "cv", "weight", "acc", "year"))
}
```

Los colores de los puntos corresponden al origen del coche (Americano, Europeo o
Japonés), se puede intuir que algunos coches gastan más en función del continente.

Como se aprecia en la gráfica, hay varias variables correlacionadas tanto positiva
como negativamente. Pero a nosotros solo nos interesan las relacionadas con el 
consumo de combustible. Con ello en mente, podríamos decir que las variables más 
correladas son la capacidad del motor (__Displacement__), el peso y la potencia
(__horsepower__) del coche. Veámoslas mejor:

```{r plotting corr vars, echo = F}
v <- Auto %>% dplyr::select(mpg, horsepower, weight, displacement, origin)

ggplot2::ggplot(data = v, aes(horsepower, mpg)) + 
  geom_point(aes(colour = origin)) + 
  theme_bw() + 
  scale_color_discrete(name = "Origin", labels = c("American", "European", "Japanese"))

ggplot2::ggplot(data = v, aes(weight, mpg)) + 
  geom_point(aes(colour = origin)) + 
  theme_bw() + 
  scale_color_discrete(name = "Origin", labels = c("American", "European", "Japanese"))

ggplot2::ggplot(data = v, aes(displacement, mpg)) + 
  geom_point(aes(colour = origin)) + 
  theme_bw() + 
  scale_color_discrete(name = "Origin", labels = c("American", "European", "Japanese"))
rm(v)
```

Veamos ahora la correlación mediante `boxplot`:

```{r Boxplots, echo = F}
# A car has a low fuel comsumption if mpg is higher (It travels more milles per gallon of fuel).
# Consider the cars with mpg above the median as low consumption (1), and high
# comsumption those bellow the median
Auto <- dplyr::mutate(Auto, mpg01 = as.factor(ifelse(mpg > median(mpg), 1, 0)))

bp1 <- ggplot(Auto) + geom_boxplot(aes(mpg01, cylinders)) + labs(x = "")
bp2 <- ggplot(Auto) + geom_boxplot(aes(mpg01, displacement)) + labs(x = "")
bp3 <- ggplot(Auto) + geom_boxplot(aes(mpg01, horsepower)) + labs(x = "")
bp4 <- ggplot(Auto) + geom_boxplot(aes(mpg01, weight)) + labs(x = "")
bp5 <- ggplot(Auto) + geom_boxplot(aes(mpg01, acceleration)) + labs(x = "")
bp6 <- ggplot(Auto) + geom_boxplot(aes(mpg01, year)) + labs(x = "")

grid.arrange(bp1, bp2, bp3, bp4, bp5, bp6,
             nrow = 2, ncol = 3,
             top = "Variables vs mpg01")
rm(bp1, bp2, bp3, bp4, bp5, bp6)
```

Como vemos, llegamos a la misma conclusión, la interpretación en boxplots es la
siguiente: Si los boxplots no se solapan entre sí, las variables están correladas.
Además, a mayor sea la distancia que los separa, más correladas estarán. Por tanto
salvo la aceleración y el año, el resto de variables están correladas en mayor o 
menor medida con las millas por galón de combustible que consume el coche.

- __Seleccionar las variables predictoras que considere más relevantes.__

Como hemos comentado en el punto anterior, las variables que parecen estar más
relacionadas con el consumo de combustible son `Horsepower, Weight` y `Displacement`.
Por lo tanto las usaremos como predictoras.

- __Particionar el conjunto de datos en un conjunto de entrenamiento ($80\%$) y otro
de test ($20\%$). Justificar el procedimiento usado.__

Para particionar los datos debemos asegurarnos que tanto la partición para training
como la de test mantengan la misma distribución, ya que de lo contrario podríamos
ajustar mal el modelo. Para conseguir esto, se hace uso de la librería `caret`
y su método `createDataPartition`. Ya que la variable `mpg` es contínua, se ha
decidido distribuir las muestas equitativamente en función del origien del coche.

Se ha creado un método `partitionDistribution` que muestra cómo se sigue manteniendo
la proporción de los datos tras el particionado. Esta estrategia se llama particionamiento
estratificado.

```{r EXERCISE 1.C}
partitionDistribution <- function(partition) {
  print(paste('Training: ', nrow(partition$training), 'instances'))
  print(summary(partition$training$origin) / nrow(partition$training) * 100)
  print(paste('Test: ', nrow(partition$test), 'instances'))
  print(summary(partition$test$origin)  / nrow(partition$test) * 100)
}

indexes <- createDataPartition(Auto$origin, p = .8, list = FALSE)
partition <- list(training = Auto[indexes,], test = Auto[-indexes,])
partitionDistribution(partition)
```

Podemos ver en la salida enterior como se ha mantenido la proporción de los 
orígenes de coches en ambas particiones.

- __Crear una variable binaria, `mpg01`, que será igual a $1$ si la variable `mpg`
contiene un valor por encima de la mediana, y $-1$ si `mpg` contiene un valor por
debajo. La mediana se puede calcular usando la función `median()`.__

```{r EXERCISE 1.D}
# A car has a low fuel comsumption if mpg is higher (It travels more milles per 
# gallon of fuel). Consider the cars with mpg above the median as low consumption
# (1), and high comsumption those bellow the median 
# Auto <- dplyr::mutate(Auto, mpg01 = as.factor(ifelse(mpg > median(mpg), 1, 0)))
training <- partition$training
test <- partition$test
```

- __Ajustar un modelo de regresión Logística a los datos de entrenamiento y
predecir `mpg01` usando las variables seleccionadas en b). ¿Cuál es el error
de test del modelo? Justificar la respuesta. (1 punto)__

```{r EXERCISE 1.D.1}
glm.fit <- glm(mpg01 ~ horsepower + weight + displacement, 
               data = training, 
               family = binomial)

summary(glm.fit)

# Compute the test error
glm.probs <- predict(glm.fit, newdata = test, type = "response")
glm.pred <- ifelse(glm.probs > .5, 1, 0)

confusion.table <- table(glm.pred, test$mpg01)
test.error <- mean(glm.pred != test$mpg01)*100
```

Para ajustar el modelo logístico se ha usado `glm`, la matríz de confusión es la
siguiente:

 |     	| $0$                          	| $1$                          	|
 |-----	|------------------------------	|------------------------------	|
 | $0$ 	| $`r confusion.table[1,1]`$ 	  | $`r confusion.table[1,2]`$ 	  |
 | $1$ 	| $`r confusion.table[2,1]`$ 	  | $`r confusion.table[2,2]`$ 	  |

Esta matríz muestra en la diagonal secundaria los falsos positivos
y los negativos ($`r confusion.table[1,2]`$ y $`r confusion.table[2,1]`$ respetivamente).

El error de test que hemos obtenido es del $`r test.error`\%$, lo cual 
quiere decir que estamos fallando en clasificar correctamente ese porcentaje de veces.

- __Ajustar un modelo K-NN a los datos de entrenamiento y predecir `mpg01`
usando solamente las variables seleccionadas en b). ¿Cuál es el error de
test en el modelo? ¿Cuál es el valor de K que mejor ajusta los datos?
Justificar la respuesta. (Usar el paquete class de R) (1 punto)__

```{r EXERCISE 1.D.2}
ytraining <- training %>% dplyr::select(mpg01)
training.X <- training %>% dplyr::select(horsepower, weight, displacement)
training.X <- scale(training.X)
test.X <- test %>% dplyr::select(horsepower, weight, displacement)
test.X <- scale(test.X)[,]

data <- data.frame(train = training.X, y = ytraining)

# Find the best k with cross validation with 10 partitions
k <- e1071::tune.knn(data[,-4], data[,4], k = 1:30, 
                     tunecontrol = tune.control(sampling = "cross"))
k <- k$best.parameters$k

pred <- class::knn(data[,-4],
                   test.X,
                   data[,4],
                   k = k,
                   prob = T)

prob <- attr(pred, "prob")

# this is necessary because k-NN by default outputs
# the posterior probability of the winning class
prob[pred == 0] <- 1 - prob[pred == 0]

confusion.table <- table(pred, test$mpg01)
test.error <- mean(pred != test$mpg01)*100

rm(data, cl)
```

Primero preparamos los datos necesarios para aplicar `class:knn`, luego se ha
buscado el mejor valor de `k` comprendido entre $1$ y $30$, el mejor ha sido
$`r k`$. Con este valor para `k` se ha obtenido la siguiente matriz de confusión:

|     	| $0$                          	| $1$                          	|
|-----	|------------------------------	|------------------------------	|
| $0$ 	| $`r confusion.table[1,1]`$ 	  | $`r confusion.table[1,2]`$ 	  |
| $1$ 	| $`r confusion.table[2,1]`$ 	  | $`r confusion.table[2,2]`$ 	  |

Y un error de test de $`r test.error`\%$, el cual es bastante bueno.

Se probó a buscar un valor para `k` usando `tune.knn`, pero se obtenían peores
resultados para los valores de `k` propuestos.

En cuanto a la eleccion de `k` no es tarea fácil, ya que en función de la elección
podemos obtener efectos muy variantes en el clasificador. Una regla que puede 
servir de guía es que a medida que `k` aumenta, la frontera de decisión se vuelve
más rígida (Más lineal), y a medida que decrece es más flexible. Por tanto es
importante encontrar un punto medio para no obtener ni sobreajuste ni demasiado
error en la clasificación

- __Pintar las curvas ROC (instalar paquete ROCR en R) y comparar y valorar los
resultados obtenidos para ambos modelos. (0.5 puntos)__

```{r EXERCISE 1.D.3}
ROCCurve <- function(data) {
  # Draw a ROC curve
  #
  # Args:
  #   data: Data frame with three columns (M for predicted objects, D for true
  #         classes and model if more than one ROC curve wants to be drawn)
  #   
  # Returns:
  #   The Area Under ROC Curve (AUC)
  # TODO: Check dataframe columns (Error handling)
  g <- ggplot(data, aes(d = D, m = M, color = model)) + geom_roc(n.cuts = 0) + style_roc()
  auc <- round(calc_auc(g), 6)
  g <- g + annotate("text", x = .75, y = .25, 
                    label = paste("AUC_knn = ", auc$AUC[2], "\nAUC_glm = ", auc$AUC[1]))

  print(g)
  
  list(auc$AUC[2], auc$AUC[1])
}

pred.object.knn <- prediction(as.numeric(prob), as.numeric(test$mpg01))
pred.object.glm <- prediction(glm.probs, test$mpg01)

data <- data.frame(M = c(unlist(attr(pred.object.knn, "predictions")), unlist(attr(pred.object.glm, "predictions"))),
                   D = c(unlist(attr(pred.object.knn, "labels")), unlist(attr(pred.object.glm, "labels"))),
                   model = c(rep("knn", 77), rep("glm", 77)))
auc <- ROCCurve(data)
```

En el código anterior se han pintado y calculado las curvas _ROC_ para `KNN` y 
regresión logística (`glm`). Como se puede apreciar en las gráficas, el clasificador
que obtiene mejores resultados es `knn`. Esto se pone de manifiesto si calculamos
el área bajo la curva _ROC_. A mayor área, mejor rendimiento tiene el clasificador.
En concreto, $AUC_{knn} = `r auc[1]`$ y $AUC_{glm} = `r auc[2]`$

- __Bonus-1. (1 punto) Estimar el error de test de ambos modelos (`RL, K-NN`) pero
usando Validación Cruzada de 5-particiones. Comparar con los resultados
obtenidos en el punto anterior.__

- __Bonus-2 (1 punto): Ajustar el mejor modelo de regresión posible considerando
la variable `mpg` como salida y el resto como predictoras. Justificar el modelo
ajustado en base al patrón de los residuos. Estimar su error de entrenamiento y
test.__

# Ejercicio 2

__Usar la base de datos `Boston` (en el paquete MASS de R) para ajustar un modelo que
prediga si dado un suburbio este tiene una tasa de criminalidad (`crim`) por encima o
por debajo de la mediana. Para ello considere la variable `crim` como la variable salida y
el resto como variables predictoras.__

- __Encontrar el subconjunto óptimo de variables predictoras a partir de un
modelo de regresión-LASSO (usar paquete `glmnet` de R) donde seleccionamos
solo aquellas variables con coeficiente mayor de un umbral prefijado. (1
punto)__

```{r EXERCISE 2.1}

```


- __Ajustar un modelo de regresión regularizada con “`weight-decay`” (`ridge-regression`) 
y las variables seleccionadas. Estimar el error residual del modelo
y discutir si el comportamiento de los residuos muestran algún indicio de
“underfitting”. (1 punto)__

- __Definir una nueva variable con valores -1 y 1 usando el valor de la mediana de
la variable `crim` como umbral. Ajustar un modelo SVM que prediga la nueva
variable definida. (Usar el paquete `e1071` de R). Describir con detalle cada
uno de los pasos dados en el aprendizaje del modelo SVM. Comience
ajustando un modelo lineal y argumente si considera necesario usar algún
núcleo. Valorar los resultados del uso de distintos núcleos. (1 punto)__

- __Bonus-3 (1 punto): Estimar el error de entrenamiento y test por validación cruzada de
5 particiones.__
